g1 <- HSfbgraphcore # (82,513)
g2 <- HSfrgraphcore # (82,214)
W <- intersect(V(g1),V(g2)) # shared vertices
}
# Chunk 3: seed
# Randomly select x and S from W, the shared vertices
(x <- sample(W,1))
W <- setdiff(W,x) # exclude x from W
maxseed <- min(length(W),s)
(S <- sort(sample(W,maxseed)))
# Chunk 4: sgm
# Determine Sx and C'x, then do SGM
NBDS <- vnsgm(x,S,g1,g2,h,ell,R,gamma,plotF=TRUE)
str(NBDS)
library(VN)
# Chunk 1: setup
#<link rel="stylesheet" href="http://vis.supstat.com/assets/themes/dinky/css/scianimator.css">
#<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
#<script src="http://vis.supstat.com/assets/themes/dinky/js/jquery.scianimator.min.js"></script>
suppressMessages(require(igraph))
suppressMessages(require(VN))
suppressMessages(require(Matrix))
suppressMessages(require(lattice))
suppressMessages(require(popbio))
suppressMessages(require(ggplot2))
suppressMessages(require(reshape2))
suppressMessages(require(knitr))
suppressMessages(require(printr))
suppressMessages(require(dplyr))
options(digits = 2)
source("~/Dropbox/SGM/nbdmaking/vn.R")
#knitr::opts_chunk$set(cache=TRUE, autodep=TRUE)
#dep_auto() # figure out dependencies automatically
opts_chunk$set(cache=FALSE,echo=TRUE,eval=TRUE,warning=FALSE,message=FALSE,comment="#",
dpi=100,dev=c('png','pdf'))
opts_knit$set(aliases=c(h='fig.height', w='fig.width', cap='fig.cap', scap='fig.scap'))
opts_knit$set(eval.after = c('fig.cap','fig.scap'))
knit_hooks$set(document = function(x) {                                                                gsub('(\\\\end\\{knitrout\\}[\n]+)', '\\1\\\\noindent ', x)                                  })
opts_knit$set(animation.fun = hook_scianimator)
#knit_hooks$set(plot = function(x, options) {
#       paste('<figure><img src="',
#             opts_knit$get('base.url'), paste(x, collapse = '.'),
#             '"><figcaption>', options$fig.cap, '</figcaption></figure>',
#             sep = '')
# })
fn = local({
i = 0
function(x) {
i <<- i + 1
#     paste('Figure ', i, ': ', x, sep = '')
paste('', '', x, sep = '')
}
})
rmd.convert <- function(fname, output=c('latex', 'word', 'html', "pdf")){
## Thanks to Robert Musk for helpful additions to make this run better on Windows
require(knitr)
require(tools)
thedir <- file_path_as_absolute(dirname(fname))
thefile <- (basename(fname))
create_latex <- function(f){
knit(f, 'tmp-outputfile.md');
newname <- paste0(file_path_sans_ext(f), ".tex")
mess <- paste('pandoc -f markdown -t latex -s -o', shQuote(newname),
"tmp-outputfile.md")
system(mess)
cat("The Latex file is", file.path(thedir, newname),
"\nIf transporting do not forget to include the folder", file.path(thedir, "figure"), "\n")
mess <- paste('rm tmp-outputfile.md')
system(mess)
}
create_word <- function(f){
knit(f, 'tmp-outputfile.md');
newname <- paste0(file_path_sans_ext(f),".docx")
mess <- paste('pandoc -f markdown -t docx -o', shQuote(newname), "tmp-outputfile.md")
system(mess)
cat("The Word (docx) file is", file.path(thedir, newname), "\n")
mess <- paste('rm tmp-outputfile.md')
system(mess)
}
create_html <- function(f){
knit2html(f)
cat("The main HTML file is", file.path(thedir, paste0(file_path_sans_ext(f), ".html")),
"\nIf transporting do not forget to include the folder", file.path(thedir, "figure"), "\n")
}
create_pdf <- function(f){
knit(f, 'tmp-outputfile.md');
newname <- paste0(file_path_sans_ext(f),".pdf")
mess <- paste('pandoc -f markdown -o', shQuote(newname), "tmp-outputfile.md")
system(mess)
cat("The PDF file is", file.path(thedir, newname), "\n")
mess <- paste('rm tmp-outputfile.md')
system(mess)
}
origdir <- getwd()
tryCatch({
setwd(thedir) ## put us next to the original Rmarkdown file
out <- match.arg(output)
switch(out,
latex=create_latex(thefile),
html=create_html(thefile),
pdf=create_pdf(thefile),
word=create_word(thefile)
)}, finally=setwd(origdir))
}
##################
rmarkdownTable <- function(df) {
cat(paste(names(df), collapse = "|"))
cat("\n")
cat(paste(rep("-", ncol(df)), collapse = "|"))
cat("\n")
for(i in 1:nrow(df)){
cat(paste(df[i,], collapse = "|"))
cat("\n")
}
invisible(NULL)
}
#require(xtable)
#tab <- xtable(head(iris),digits=2)
#print(tab, type="html")
#(http://www.cis.jhu.edu/~parky/XDATA/SGM/27SGM_for_VN_20160518.pdf)
# Chunk 2: toy1
suppressMessages(require(VN)) ||  install.packages("http://username:password@www.cis.jhu.edu/~parky/XDATA/SGM/VN_0.1.0.tar.gz",type="source",method="wget")
suppressMessages(require(igraph))
sim <- TRUE # if TRUE, run simulation, otherwise do the HS experiment
HS <- "full" # or "core"
# parameters for finding seeds
s <- ifelse(sim,4,12) # number of seeds to be used for SGM
h <- ell <- 1 # max walk for finding neighborhoods
# parameters for SGM
R <- 100     # repeat SGM R times to get averaged P matrix
gamma <- 0.1 # number of iterations for the Frank-Wolfe algorithm
mc <- 2
set.seed(1234+mc)
if (sim) {
# generate a pair of correlated graphs
m <- 5  # |J| = junk on G1
n <- 20 # |W| = shared vertices on G1, not including x and S
mp <- 0 # |J'| = junk on G2
d <- 5  # for RDPG, dimension of the random vectors
corr <- 0.5 # for correlated graphs
(nV1 <- 1+s+n+m)
(nV2 <- 1+s+n+mp)
lpvs <- sample_sphere_surface(dim=d, n=nV1)/1.5 # random vectors for RDPG
gg <- rdpg.sample.correlated(t(lpvs),corr)
g1 <- gg[[1]];
g2 <- gg[[2]];
g2 <- delete_vertices(g2,v=(nV2+1):nV1); # remove m vertices from G' to make |V(G)| != |V(G')|
W <- intersect(V(g1),V(g2)) # shared vertices
} else {
data("HSgraphs")
if (HS == "full") {
# rearrange the vertices so that the to-be-selected seeds are valid
perm.fb <- c(coremap[,1],setdiff(1:vcount(HSfbgraphfull),coremap[,1]))
perm.fr <- c(coremap[,2],setdiff(1:vcount(HSfriendsgraphfull),coremap[,2]))
g1 <- permute.vertices(HSfbgraphfull,perm.fb) # (156,1437)
g2 <- permute.vertices(HSfriendsgraphfull,perm.fr) # (134,668)
W <- 1:nrow(coremap) # seeds should be selected from the shared (core) vertices
} else { # core graphs
g1 <- HSfbgraphcore # (82,513)
g2 <- HSfrgraphcore # (82,214)
W <- intersect(V(g1),V(g2)) # shared vertices
}
# Chunk 3: seed
# Randomly select x and S from W, the shared vertices
(x <- sample(W,1))
W <- setdiff(W,x) # exclude x from W
maxseed <- min(length(W),s)
(S <- sort(sample(W,maxseed)))
# Chunk 4: sgm
# Determine Sx and C'x, then do SGM
NBDS <- vnsgm(x,S,g1,g2,h,ell,R,gamma,plotF=TRUE)
str(NBDS)
library(VN)
require(rmarkdown)
render("vignette/vn.Rmd")
library(VN)
A = matrix(1,9,9)
rownames(A) = sample(9)
A
A[sample(9),sample(9)]
matrix(3:8,10)
cbind(matrix(3:8,10), matrix(2:7, 10))
library(VN)
n=1000
system.time(A <- B <- C <- matrix(0,n,n))
system.time(A <- matrix(0,n,n); B <- matrix(0,n,n); C <- matrix(0,n,n))
library(VN)
require(igraph)
require(Matrix)
g = sample_gnp(100,0.1)
A = g[]
class(A)
B = g[]
#seeds are assumed to be vertices 1:m in both graphs
totv1<-ncol(A)
totv2<-ncol(B)
A[A==0]<- -1
B[B==0]<- -1
diff<-totv1-totv2
for (j in 1:diff){B<-cbind(rbind(B,pad),pad)}
pad=0
totv<-max(totv1,totv2)
m=10
n<-totv-m
A12<-rbind(A[1:m,(m+1):(m+n)])
A21<-cbind(A[(m+1):(m+n),1:m])
B12<-rbind(B[1:m,(m+1):(m+n)])
B21<-cbind(B[(m+1):(m+n),1:m])
A22<-A[(m+1):(m+n),(m+1):(m+n)]
B22<-B[(m+1):(m+n),(m+1):(m+n)]
tol<-1
n
s
S = diag(100)
S[11:100, 11:100] = rsp(90, g=0.5)
require(VN)
S[11:100, 11:100] = rsp(90, g=0.5)
start = S
P<-start
toggle<-1
iter<-0
x<- A21%*%t(B21)
y<- t(A12)%*%B12
iter<-iter+1
z<- A22 %*% P %*% Matrix::t(B22)
class(A22)
class(B22)
class(P)
P <- Matrix(start)
z<- A22 %*% P %*% Matrix::t(B22)
dim(A22)
dim(P)
dim(S)
P = P[1:90,1:90]
z<- A22 %*% P %*% Matrix::t(B22)
w<- Matrix::t(A22) %*% P %*% B22
Grad<-x+y+z+w;
mm=max(abs(Grad))
ind<-clue::solve_LSAP(Grad+matrix(mm,totv-m,totv-m), maximum =TRUE)
mm=max(abs(Grad))
class(mm)
ind<-clue::solve_LSAP(Grad+matrix(mm,totv-m,totv-m), maximum =TRUE)
class(mm)
class(totv)
class(m)
require(clue)
ind<-clue::solve_LSAP(Grad+matrix(mm,totv-m,totv-m), maximum =TRUE)
?solve_LSAP
class(Grad)
ind<-clue::solve_LSAP(matrix(Grad)+matrix(mm,totv-m,totv-m), maximum =TRUE)
ind<-clue::solve_LSAP(as.matrix(Grad)+matrix(mm,totv-m,totv-m), maximum =TRUE)
T<-Diagonal(n)
T<-T[ind,]
class(ind)
str(ind)
ind<-matrix(clue::solve_LSAP(as.matrix(Grad)+matrix(mm,totv-m,totv-m), maximum =TRUE))
T<-Diagonal(n)
T<-T[ind,]
str(ind)
dim(T)
n
T<-diag(n)
T<-T[ind,]
class(T)
wt<-Matrix::t(A22) %*% T %*% B22
class(T)
dim(T)
str(ind)
wt<-Matrix::t(A22) %*% T %*% B22
c<-sum(diag(w%*%Matrix::t(P)))
d<-sum(diag(wt%*%Matrix::t(P)))+sum(diag(w%*%Matrix::t(T)))
e<-sum(diag(wt%*%Matrix::t(T)))
u<-sum(diag(Matrix::t(P)%*%x+Matrix::t(P)%*%y))
v<-sum(diag(Matrix::t(T)%*%x+Matrix::t(T)%*%y))
if( c-d+e==0 && d-2*e+u-v==0){
alpha<-0
}else{
alpha<- -(d-2*e+u-v)/(2*(c-d+e))}
f0<-0
f1<- c-e+u-v
falpha<-(c-d+e)*alpha^2+(d-2*e+u-v)*alpha
if(alpha < tol && alpha > 0 && falpha > f0 && falpha > f1){
P<- alpha*P+(1-alpha)*T
}else if(f0 > f1){
P<-T
}else{
toggle<-0}
library(VN)
?crossprod
library(VN)
?synchronize
require(microbenchmark)
?synchronize
synchronize
require(devtools)
install_github("Noobivsho/ssClust")
rm(list=ls())
setwd("~/Dropbox/VN2/ssVNCodesAndTutorial")
################################ DEPENDS ################################
if(!library(ssClust, logical.return = TRUE)) install.packages("ssClust", repos = NULL, type="source") #From this directory, R CMD INSTALL ssClust
#library(devtools)
#reload(inst("ssClust"))
library(ssClust)
#library(devtools)
#reload(inst("ssClust"))
#library(ssClust)
library("igraph")
################################ END DEPENDS ################################
getAvgPrecision <- function(k, isCorrectInNominateOrder){
vecprecis = rep(NA, k)
for (i in 1:k){
vecprecis[i] = sum(isCorrectInNominateOrder[1:i])/i
}
mean(vecprecis)
}
makeGraphWithErrorBars<-function(x.vals,
y.vals,
y.sd,
x.label.name,
y.label.name,
y.limits=NULL,
col="blue",
lty=2,mainTitle=NULL,
cex=2,
add=F){
barwidth=0.1
delta = 2*y.sd
y.observed.limits <- c(min(y.vals-delta),max(y.vals+delta))
diffBetweenYLimits <- round(y.observed.limits[2]-y.observed.limits[1],2)
if(is.null(y.limits))
y.limits <- c(y.observed.limits[1]-diffBetweenYLimits/10, y.observed.limits[2]+diffBetweenYLimits/10)
if(is.null(mainTitle))mainTitle=paste0(x.label.name, " vs. ", y.label.name)
if(!add){
plot(x.vals,
y.vals,
main=mainTitle,
xlab=x.label.name,
ylab=y.label.name,
ylim=y.limits,
type='l',
lty = lty,
col = col,
lwd=2,
cex.lab=cex,
cex.main=cex)#,
} else{
lines(x.vals,
y.vals,
type='l',
lty = lty,
col = col,
lwd=2)
}
# xaxt="n")
#axis(1, at=x.vals, labels=x.vals,  col.axis="black", las=2)
segments(x.vals,y.vals-delta,x.vals,y.vals+delta)
segments(x.vals-barwidth,y.vals+delta,x.vals+barwidth,y.vals+delta)
segments(x.vals-barwidth,y.vals-delta,x.vals+barwidth,y.vals-delta)
}
oneMCRep<-function(n,numKnownNotRed){
#matching Li's simulation parameters
rho <- c(0.4,0.3,.3)
B1 <- matrix(c(0.5,0.3,.4,
0.3,0.8,.6,
.4,0.6, .3),  nrow = 3,ncol=3)
B2 <- matrix(.5 ,nrow = 3,ncol=3)
if(n==10)
nu=1
if(n==500)
nu = .3
if(n==10000)
nu = .1
B = nu*B1 + (1-nu)*B2
numKnownRed =20
blockSizes <- n*rho + c(numKnownRed,0,0)
#simulate graph
A.igraph<- sbm.game(n+numKnownRed, pref.matrix = B, block.sizes = blockSizes, directed = F, loops = F)
#shovel into obj we need
A <- NULL
A$adj <- get.adjacency(A.igraph)
#tau is actual labels
A$tau <- rep(1,blockSizes[1])
A$tau <- c(A$tau, rep(2, blockSizes[2]))
A$tau <- c(A$tau, rep(3, blockSizes[3]))
redGroup = min(A$tau)
#semi-supervise
if(n ==10)
knownRed <- sample(which(A$tau==redGroup),4)
if(n ==500)
knownRed <- sample(which(A$tau==redGroup),20)
if(n ==10000)
knownRed <- sample(which(A$tau==redGroup),40)
#more semi-supervision
knownNotRed <- sample(which(A$tau!=1),
numKnownNotRed)
#cluster and nominate
ss = ssVN(adj=A$adj,
embeddingDim=3,
knownRed = knownRed,
knownNotRed = knownNotRed,
initializationStrategy = "kpp",
Grange=2:5)
#order based on posterior prob of class membership.  I suppose the first #(semi-sup) will be easy money
theOrder <- order(ss$redRanking[-knownRed], decreasing = T)
#for mean average position, check if the actual label is red
isCorrect <- as.integer(A$tau==1)[theOrder]
#using Li's codes, get avg precision at n_1
avgPrecision = getAvgPrecision(blockSizes[1], isCorrect)
#   numCorrect = sum(ss$ssClustObj$cl[A$tau==redGroup]==redGroup)
#   accuracy = numCorrect/sum(A$tau==redGroup)
return(c(avgPrecision, isCorrect))
}
################################ CONFIGURABLES ################################
n=500
MCR=100
numNumKnownNotRed <- 6
numKnownNotRedPerJ <- 20
set.seed(213908123)
################################ MAIN LOOP ################################
probDf = NULL
#increasing number of known not red (keeping number of red known = 20).
meanAvgPrec <- rep(NA,numNumKnownNotRed)
sdAvgPrec <- rep(NA, numNumKnownNotRed)
for(j in 1:numNumKnownNotRed){
numKnownNotRed <- (j-1)*numKnownNotRedPerJ
#   res <- foreach(i=1:MCR, .combine=rbind) %dopar% {
#     oneResult = oneMCRep(n,numKnownNotRed = numKnownNotRed)
#     return(oneResult)
#   }
res <- rep(NA, MCR)
prs = matrix(NA,nrow = MCR, ncol = 500)
for(i in 1:MCR){
print(i)
out <-oneMCRep(n, numKnownNotRed=numKnownNotRed)
res[i] = out[1]
prs[i,] = out[-1]
}
meanAvgPrec[j] <- mean(res)
sdAvgPrec[j]<-sd(res)
save.image('intermedRes.RData')
nomOrder <- 1:500
prRed = colMeans(prs)
sdRed = apply(prs,2,sd)/sqrt(MCR)
tempPrDf = data.frame(nomOrder = nomOrder,
prRed = prRed,
sdRed = sdRed,
numKnownNotRed = numKnownNotRed)
probDf = rbind(probDf, tempPrDf)
}
################################ PROCESS RESULTS ################################
x.vals <- ((1:numNumKnownNotRed)-1)*numKnownNotRedPerJ
y.vals <- meanAvgPrec[1:numNumKnownNotRed]
y.sd <- sdAvgPrec[1:numNumKnownNotRed]/sqrt(MCR)
d = data.frame(map = y.vals, y.min = y.vals - 2*y.sd, y.max = y.vals + 2*y.sd, numKnownNotRed=x.vals)
d1=d
d1$method="spectral o ss-GMM"
d1<-rbind(d1,
data.frame(map=.7330, y.min = .7330,
y.max = .7330, numKnownNotRed = seq(0,100,by=20),
method = "spectral o k-means"))
######################## PLOTS ########################
library('grDevices')
library(ggplot2)
plot.0 <- ggplot(data = d1,
aes(x = numKnownNotRed, y = map, group= method, colour=method)) +
geom_line(size = 1, aes(group = method)) + theme_bw() +
geom_ribbon(aes(ymin = y.min, ymax = y.max,linetype = NA), fill='blue',alpha=0.40) +
theme(axis.title=element_text(size=12)) +theme(legend.key.size=grid::unit(.5, "cm"))+# theme(legend.justification=c(1,0), legend.position=c(1,0)) +
xlab("Number of Known Not Red Vertices") + ylab("Mean Average Precision") #+ theme(legend.position = "none")
plot.0
# x.vals <- 1:500
# y.vals <- colMeans(prs)
# y.sd <- apply(prs,2,sd)/sqrt(MCR)
# d = data.frame(map = y.vals, y.min = y.vals - 2*y.sd, y.max = y.vals + 2*y.sd, numKnownNotRed=x.vals)
# d1=d
library(ggplot2)
probDf$y.min = probDf$prRed - 2*sdRed
probDf$y.max = probDf$prRed + 2*sdRed
probDfSmall  = probDf[probDf$nomOrder<301,]
probDfSmall = probDfSmall[probDfSmall$numKnownNotRed %in% c(0, 40, 100), ]
plot.4 <- ggplot(data = probDfSmall,
aes(x = nomOrder, y = prRed, group=factor(numKnownNotRed), colour=factor(numKnownNotRed))) +
geom_line(size = 1) + theme_bw() +
#geom_ribbon(aes(x=nomOrder, ymin = y.min, ymax = y.max,linetype = NA), fill=factor(numKnownNotRed),alpha=0.40) +
theme(axis.title=element_text(size=12)) +theme(legend.key.size=grid::unit(.5, "cm"))+# theme(legend.justification=c(1,0), legend.position=c(1,0)) +
xlab("Nomination order") + ylab("Probability of being red")+ theme(legend.position = "none")
plot.4
#matching Li's simulation parameters
rho <- c(0.4,0.3,.3)
B1 <- matrix(c(0.5,0.3,.4,
0.3,0.8,.6,
.4,0.6, .3),  nrow = 3,ncol=3)
B2 <- matrix(.5 ,nrow = 3,ncol=3)
if(n==10)
nu=1
if(n==500)
nu = .3
if(n==10000)
nu = .1
B = nu*B1 + (1-nu)*B2
blockSizes <- n*rho + c(20,0,0)
#example adj matrices
A.igraph<- sbm.game(n+20, pref.matrix = B1, block.sizes = blockSizes, directed = F, loops = F)
A.pure = get.adjacency(A.igraph)
A.igraph<- sbm.game(n+20, pref.matrix = B, block.sizes = blockSizes, directed = F, loops = F)
A.s = get.adjacency(A.igraph)
image(A.pure)
image(A.s)
library(VN)
require(devtools)
?install_github
?install.packages
